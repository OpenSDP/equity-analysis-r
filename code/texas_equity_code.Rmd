---
title: "Texas Equity Metrics"
author: "Dashiell Young-Saver, Jared Knowles"
date: "Jun 30, 2018"
output: 
  html_document:
    theme: simplex
    css: ../docs/styles.css
    highlight: NULL
    keep_md: true
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

# Creating Equity Metrics
*Using Texas state testing data files*
*Programmed in R*

## Getting Started
```{r knitrSetup, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE, comment=NA}
# Set options for knitr
library(knitr)
knitr::opts_chunk$set(comment=NA, warning=FALSE, echo=TRUE,
                      root.dir = normalizePath("../"),
                      error=FALSE, message=FALSE, fig.align='center',
                      fig.width=8, fig.height=6, dpi = 144, 
                      fig.path = "../figure/E_", 
                      cache.path = "../cache/E_")
options(width=80)
```


<div class="navbar navbar-default navbar-fixed-top" id="logo">
<div class="container">
<img src="../img/open_sdp_logo_red.png" style="display: block; margin: 0 auto; height: 115px;">
</div>
</div>

### Objective

In this guide, you will be able to use standard statistics and data visuals to investigate equity in student testing outcomes along lines of race, income, gender, learning differences, English proficiency, and migrancy status.

### Using this Guide

This guide utilizes mock data from Texas's standardized exams (STAAR test, grades 3-8). Therefore, Texas districts can use this code to directly analyze the testing data files they have received from the Texas Education Agency. However, the code can be adapted to any other state or district context in which student testing outcomes are analyzed. 

Once you have identified analyses that you want to try to replicate or modify, click the 
"Download" buttons to download R code and sample data. You can make changes to the 
charts using the code and sample data, or modify the code to work with your own data. If 
you are familiar with Github, you can click "Go to Repository" and clone the entire repository to your own computer. 

Go to the Participate page to read about more ways to engage with the OpenSDP community or reach out for assistance in adapting this code for your specific context.

### About the Data

The data used in this guide was synthetically generated, and it was formatted to match the Texas Education Agency's state test file formats (Texas's file formats can be found here: https://tea.texas.gov/student.assessment/datafileformats). The data has one record per student. Out of the hundreds of features reported for each student by the Texas Education Agency, we used (and retained) the following features in our analysis: student grade level (3-8), school code, student ID, gender, race-ethnicity, economic disadvantage level, Limited English Proficiency level, and scale scores in reading, math, and writing (for the STAAR state test). We also used indicators of whether or not the student attended a Title 1 school, was a migrant, and was enrolled in special education. Here is a key of the features and their variable names in our simulated dataset:

The Texas Education Agency data files have hundreds of features attached to each student record. Coding our analyses with all of these features could get unwieldy, so the best practice is to select the key features we will need for our analyses. If you would like to directly use your own data with the code from this guide, it is best to delete unecessary features and change the headers to the feature names we chose. Below is a legend to the features we chose and how we named them. A more detailed data definition guide can be found in the `man` folder on the Github repository:

| Feature name    | Feature Description                                 |
|:-----------     |:------------------                                  |
| `grade_level`   | Grade level of exam student took (3-8)              |
| `school_code`   | School ID number                                    |
| `sid`           | Student ID number                                   |
| `male`          | Student gender                                      |
| `race_ethnicity`| Student race/ethnicity                              |
| `eco_dis`       | Student level of economic disadvantage              |
| `title_1`       | Indicator if student attends Title 1 school         |
| `migrant`       | Indicator if student is a migrant                   |
| `lep`           | Level of Limited English Proficiency                |
| `iep`           | Indicator if student enrolled in special education  |
| `rdg_ss`        | Scale score for reading exam                        |
| `math_ss`       | Scale score for math exam                           |
| `wrtg_ss`       | Scale score for writing exam                        |  
| `composition`   | Score on writing composition exam                   |

#### Loading the OpenSDP Dataset and R Packages

This guide takes advantage of the OpenSDP synthetic dataset and several key R packages. The first chunk of code below loads the R packages (make sure to install first!), and the second chunk loads the dataset and provides us with variable labels.

```{r packages, eacho=FALSE}
library(tidyverse) # main suite of R packages to ease data analysis
library(magrittr) # allows for some easier pipelines of data
library(tidyr) #
library(plyr)
library(dplyr)
library(FSA)
library(ggplot2) # to plot
library(scales) # to format
library(grid)
library(gridExtra) # to plot
# Read in some R functions that are convenience wrappers
source("../R/functions.R")
#pkgTest("devtools")
#pkgTest("OpenSDPsynthR")
```

```{r loaddataset, eacho=FALSE}
# // Step 1: Read in csv file of our dataset, naming it "texas.data"
texas.data <- read.csv("../data/synth_texas.csv")  

# // Step 2: View data file
View(texas.data)

# // Step 3: Create a vector of labels for feature names in our dataset 
#These labels will appear in visualizations and tables
labels <- c("Grade","School ID","Student ID","Gender", "Race-Ethnicity",
            "Econ Disadvantage Status","Title 1 Status","Migrancy Status",
            "LEP Status","Spec Ed Enrolled","Reading Score",
            "Math Score","Writing Score","Writing Comp Score")


#Pairs labels with feature names from file
names(labels) <- c("grade_level","school_code","sid","male","race_ethnicity",
                   "eco_dis","title_1","migrant",
                   "lep","iep","rdg_ss",
                   "math_ss","wrtg_ss","composition")

```


```{r, cache=TRUE, message=FALSE, echo=FALSE}
# Set the cache to true when using knitr to speed up future analyses
#simouts <- simpop(nstu = 40000, seed = 8763434, 
#                  control = sim_control(nschls = 12L, minyear=1996,
#                                        n_postsec = 50L,
#                                        n_cohorts = 3,
#                                        maxyear=2017)) 
#cgdata <- sdp_cleaner(simouts)
```


### About the Analyses

Especially in larger districts, students may have systematically differing educational outcomes in relation to their various identity markers (race, class, gender, English Language Learner status, etc.). These gaps often present themselves in standardized testing data, at the national, state, and local levels. The following analyses will assist your organization in seeing where gaps may exist and how wide they are, in order to spur and focus the conversation around why the gaps exist and what to do about them.

### Sample Restrictions

One of the most important decisions in running each analysis is defining the sample. 

```{r setSampleRestrictions}
# Read in global variables for sample restriction
# Agency name
#agency_name <- "Agency"

```

### Giving Feedback on this Guide
 
This guide is an open-source document hosted on Github and generated using R Markdown. We welcome feedback, corrections, additions, and updates. Please visit the OpenSDP equity metrics repository to read our contributor guidelines.

## Analyses

### Exploratory Analysis

**Purpose:** Descriptive statistics give your agency a quick snapshot of current achievement gaps among students, identifying areas for further investigation and analysis.

**Required Analysis File Variables:**

- `grade_level` 
- `school_code` 
- `male`        
- `race_ethnicity` 
- `eco_dis`      
- `title_1`     
- `migrant`     
- `lep`
- `iep`
- `rdg_ss`
- `math_ss`
- `wrtg_ss`
- `composition`

**Ask Yourself**

- How do different study subpopulations in your organization perform on standardized tests? How do they compare?
- Why do these differences occur?
- What differences do you want to explore further?

**Analytic Technique:** Calculate the summary statistics for exam performance, for all 5th and 8th grade exam takers. Note: Once you set which tests and which grade levels you would like to analyze here, the code (as written) will analyze those grade levels and tests for the rest of the guide.
```{r Averages, echo=TRUE}
# // Step 1: Set which tested grade levels to analyze (5th and 8th here)
grades <- c("5","8")

# // Step 2: Set which tested subjects to analyze (math and reading here)
subjects <- c("rdg_ss","math_ss")

# // Step 3: Calculate summary stats for each grade level
# Loop over grade level
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  print(paste("grade level: ",grade))
  a <- summary(data[,subjects]) #Summary stats table for grade
  colnames(a) <- labels[subjects]  #Label table
  print(a) #Print summary table
  
} #End loop over grade level

```

**Analytic Technique:** In order to give us a further sense of the distributions behind these summary statistics, we will create some visualizations of the data. Specifically, here we use box plots and histograms

```{r VisualizeTotals, echo=TRUE}
# // Visualization 1: Box plots
#Loop over tested subjects
for(subject in subjects){
  
  data = texas.data[texas.data$grade_level == grades,] #Isolates 5th and 8th graders
  
    #Set variables and parameters for our boxplot
    p <- ggplot(data, aes(x=as.factor(grade_level), y=data[,subject])) + 
          geom_boxplot() +
          ggtitle(paste(labels[subject], ", by Grade Level")) +
          scale_y_continuous(name=labels[subject]) +
          scale_x_discrete(name="Grade Level")
    print(p) 
    

} #End loop over tested subjects

# // Comparison 2: Histograms of scores for eco_dis students
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  #Loop over tested subject
  for(subject in subjects){ 
    #Set variables and parameters for our boxplot
    p <- ggplot(data, aes(x=data[,subject])) + 
          ggtitle(paste("Grade: ",grade,", ",labels[subject], " (all students)"))+
          geom_histogram(alpha = 0.5, binwidth = 50, fill = "dodgerblue", color = "dodgerblue") + 
          scale_x_continuous(name=paste(labels[subject])) 
    print(p) 
    
  } #End loop over tested subject
  
} #End loop over grade level
```

**Analytic Technique:** Now that we have some measures for the performance on exams among all of our students, we can create those same measures for our various subpopulations of students. We will start by comparing descriptive statistics among different student demographic populations (income, race, and gender).

```{r DescriptiveDemographics, echo=TRUE}
# // Step 1: Initialize Demographics to Analyze
#Vector with features we want to analyze: Econ Disadvantage, Race Ethnicity, Gender
dems <- c("eco_dis","race_ethnicity","male")

# // Comparisons: Generating summary stats for Eco Dis, Race Ethnicity, and Gender
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  #Loop over tested subject
  for(subject in subjects){
    
    print(paste("Grade: ",grade,", ",labels[subject])) #Print subject and grade level
    
    #Loop over demographic features
    for(dem in dems){
      
      a<-Summarize(data[,subject] ~ data[,dem]) #Makes comparison table
      colnames(a)[1] <- labels[dem] #Labels comparison table
      print(a) #Prints comparison table
      
    } #End loop over demogrpahic features
    
  } #End loop over tested subject
  
} #End loop over grade level

```

**Analytic Technique:** In addition to these raw numbers, it will help to visualize these comparisons, to give us a sense of scale and shape in these gaps. To do so, we will use both box plots and histograms.

```{r VisualizeEcoDis, echo=TRUE}
# // Step 1: Initialize a set of distinguishable colors for graphics
colors <- c("red","dodgerblue3","green","coral","violet","burlywood2","grey68")

# // Comparison: Box plots and histograms of scores for Econ Disadvantage, Race, and Gender
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  #Loop over tested subject
  for(subject in subjects){
    
    #Loop over demographic features
    for(dem in dems){
      
        #Set variables and parameters for our boxplot
        bp <- ggplot(data, aes(x=as.factor(data[,dem]), y=data[,subject])) + 
              geom_boxplot() +
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", by ",labels[dem])) +
              scale_y_continuous(name=labels[subject]) +
              scale_x_discrete(name=labels[dem])
        print(bp) #Print box plot
        
        #Set variables and parameters for our histogram
        h <- ggplot(data, aes(x=data[,subject], fill = as.factor(data[,dem]))) + 
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", by ",labels[dem]))+
              geom_histogram(alpha = 0.5, binwidth = 50) + 
              scale_fill_manual(name=labels[dem],
                                values=colors[1:length(levels(as.factor(data[,dem])))])+
              scale_x_continuous(name=paste(labels[subject], ", Grade", grade)) 
        print(h) #Print histogram
      
    }#End loop over demographic features
    
  } #End loop over tested subject
  
} #End loop over grade level
```


**Analytic Technique:** Next we will extend these comparisons to different student status populations, in relation to special education, migrancy status, and LEP status. It's the same code, but now we just change our demographic indicators to the new ones we'd like to analyze (how convenient!). We start with the descriptive statistics in this first chunk, then move to visualizations in the next chunk.

```{r DescriptiveStatus, echo=TRUE}
# // Step 1: Initialize Demographics to Analyze
#Vector with features we want to analyze: Special Education, Migrancy, and LEP Status
##NOTE MIGRANCY DATA JUST 'NAs' SO NOT INCLUDED YET IN ANALYSIS##
dems <- c("iep","lep")

# // Comparisons: Generating summary stats for Spec Ed, Migrancy, and LEP
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  #Loop over tested subject
  for(subject in subjects){
    
    print(paste("Grade: ",grade,", ",labels[subject])) #Print subject and grade level
    
    #Loop over demographic features
    for(dem in dems){
      
      a<-Summarize(data[,subject] ~ data[,dem]) #Makes comparison table
      colnames(a)[1] <- labels[dem] #Labels comparison table
      print(a) #Prints comparison table
      
    } #End loop over demogrpahic features
    
  } #End loop over tested subject
  
} #End loop over grade level

```

Now for visualizations:

```{r VisualizeStatus, echo=TRUE}
# // Comparison: Box plots and histograms of scores for Special Education, Migrancy, and LEP Status
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  #Loop over tested subject
  for(subject in subjects){
    
    #Loop over demographic features
    for(dem in dems){
      
        #Set variables and parameters for our boxplot
        bp <- ggplot(data, aes(x=as.factor(data[,dem]), y=data[,subject])) + 
              geom_boxplot() +
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", by ",labels[dem])) +
              scale_y_continuous(name=labels[subject]) +
              scale_x_discrete(name=labels[dem])
        print(bp) #Print box plot
        
        #Set variables and parameters for our histogram
        h <- ggplot(data, aes(x=data[,subject], fill = as.factor(data[,dem]))) + 
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", by ",labels[dem]))+
              geom_histogram(alpha = 0.5, binwidth = 50) + 
              scale_fill_manual(name=labels[dem],
                                values=colors[1:length(levels(as.factor(data[,dem])))])+
              scale_x_continuous(name=paste(labels[subject], ", Grade", grade)) 
        print(h) #Print histogram
      
    }#End loop over demographic features
    
  } #End loop over tested subject
  
} #End loop over grade level
```

**Analytic Technique:** Often, it can be helpful to look at the intersections of the demographic data we pulled. In particular, exploring possible gaps among combinations of race, socioeconomic status, gender, and student label status (LEP, Spec Ed, Migrancy, etc.) can elucidate further achievement gaps in the data. Here, we will explore two intersections: race-ethnicity and gender as well as socioeconomic status and special education enrollment.

We start with descriptive statistics:

```{r DescriptiveCombos, echo=TRUE}
# // Analysis 1: Comparing within groups--Gender gaps within race

#Set the feature you would like to compare within
group.by <- "race_ethnicity"

#Set the feature you are comparing
compare.by <- "male"

# Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  res <- levels(as.factor(data[,group.by])) #All the different race-ethnicities we will explore
  
  #Loop over tested subject
  for(subject in subjects){
    
    print(paste("Grade: ",grade,", ",labels[subject])) #Print subject and grade level
    
    #Loop over race-ethnicities
    for(re in res){
      
      #Isolates observations from particular race-ethnicity
      data.res <- data[data[,group.by]==re,]
      
      #Makes comparison table across genders within each race-ethnicity group
      a<-Summarize(data.res[,subject] ~ data.res[,compare.by]) #Makes comparison table
      colnames(a)[1] <- labels[compare.by]
      print(paste(labels[group.by],": ",re))
      print(a) #Prints comparison table
      
    } #End loop over race-ethnicities
    
    cat("\n\n") #spacer line
    
  } #End loop over tested subject
  
} #End loop over grade level

# // Analysis 2: Comparing proportions enrolled in a program
#This analysis will compare what percentage of each econ_dis category has an IEP
#First will look at proportions among all grade levels
cont.table <- with(texas.data, table(eco_dis,iep))

cont.table #Frequency table
round(prop.table(cont.table,1)*100) #Proportion contingency table

#Now we will look at proportions within grade levels
#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  
  print(paste("Grade: ",grade)) #Print grade level
  
  cont.table <- with(data, table(eco_dis,iep))
  print(cont.table) #Frequency table
  print(round(prop.table(cont.table,1)*100)) #Proportion contingency table
  
} #End loop over grade level

# // Analysis 3: Comparing within groups--Special Ed gaps within Socioeconomic levels
#Note: same code as analysis 1, just with different set features in first lines
#Set the feature you would like to compare within
group.by <- "eco_dis"

#Set the feature you are comparing
compare.by <- "iep"

# Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  res <- levels(as.factor(data[,group.by])) #All the different levels of economic disadvantage
  
  #Loop over tested subject
  for(subject in subjects){
    
    print(paste("Grade: ",grade,", ",labels[subject])) #Print subject and grade level
    
    #Loop over levels of econ-dis
    for(re in res){
      
      #Isolates observations from particular econ-dis level
      data.res <- data[data[,group.by]==re,]
      
      #Makes comparison table for special ed enrollemnt within econ-dis level
      a<-Summarize(data.res[,subject] ~ data.res[,compare.by]) #Makes comparison table
      colnames(a)[1] <- labels[compare.by]
      print(paste(labels[group.by],": ",re))
      print(a) #Prints comparison table
      
    } #End loop over econ-dis level
    
    cat("\n\n") #spacer line
    
  } #End loop over tested subject
  
} #End loop over grade level

```

We continue with data visuals:

```{r VisualizeCombos, echo=TRUE}
# // Comparison: Box plots and histograms of scores comparing gender within race-ethnicity

#Set the feature you would like to compare within
group.by <- "race_ethnicity"

#Set the feature you are comparing
compare.by <- "male"

#Loop over grade levels
for(grade in grades){
  
  data = texas.data[texas.data$grade_level == grade,] #Isolates grade level
  res <- levels(as.factor(data[,group.by])) #All the different race-ethnicities we will explore
  
  #Loop over tested subject
  for(subject in subjects){
    
    #Loop over demographic features
    for(re in res){
      
        #Isolates observations from particular race-ethnicity
        data.res <- data[data[,group.by]==re,]
      
        #Set variables and parameters for our boxplot
        bp <- ggplot(data.res, aes(x=as.factor(data.res[,compare.by]), y=data.res[,subject])) + 
              geom_boxplot() +
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", ",re)) +
              scale_y_continuous(name=labels[subject]) +
              scale_x_discrete(name=labels[compare.by])
        print(bp) #Print box plot
        
        #Set variables and parameters for our histogram
        h <- ggplot(data.res, aes(x=data.res[,subject], fill = as.factor(data.res[,compare.by]))) + 
              ggtitle(paste("Grade: ",grade,", ", labels[subject],", ",re))+
              geom_histogram(alpha = 0.5, binwidth = 50) + 
              scale_fill_manual(name=labels[compare.by],
                                values=colors[1:length(levels(as.factor(data.res[,compare.by])))])+
              scale_x_continuous(name=paste(labels[subject], ", Grade", grade)) 
        print(h) #Print histogram
      
    }#End loop over race-ethnicity
    
  } #End loop over tested subject
  
} #End loop over grade level
```

### Comparing gaps at schools

**Purpose:** When you already have a sense of where the gaps exist throughout the district, it can be useful to pinpoint at which schools the gap is most exaggerated and at which schools the gap is most narrow. Identifying these schools can lead to further analyses to investigate why these variations exists, possibly informing school and district policy. 

**Required Analysis File Variables:**

- `grade_level` 
- `school_code` 
- `male`        
- `race_ethnicity` 
- `eco_dis`      
- `title_1`     
- `migrant`     
- `lep`
- `iep`
- `rdg_ss`
- `math_ss`
- `wrtg_ss`
- `composition`

**Ask Yourself**

- Where are the gaps most exaggerated? Where are the gaps narrowest?
- What further analyses could we do to investigate the reasons behind gap variation at different schools?

**Analytic Technique:** We will be calculating achievement gaps using median scores on state tests for our subpopulations. We have decided to use medians, rather than means, because the distributions for our test scores (as shown in the histograms above) tend to be skewed left or right. With such skew, means can often be inflated or deflated due to outliers. Medians, which are less sensitive to skew, are often more effective measures of central tendency in such cases. 

We will quantify the gaps according to the state-wide standard deviation for the year, test, and grade level in which the gap exists. Here is a table showing the distribution info (including standard deviation) for all the tests from 2014 (all state education agencies should report something like this):

<img src="../img/staar_2014_dist.png" style="display: block; margin: 0 auto; height: 350px;">

Since we found above that the gender gap in math and the LEP status gap in reading were the widest gaps district-wide, we will focus on quantifying those gaps within the schools.

```{r SchoolGaps, echo=TRUE}
# // Step 1: Initialize table of scale score standard deviations for our tests
#Import csv file I made with standard deviations in scale scores for all exams
sd.table <- read.csv("../data/sd_table.csv")
View(sd.table)

#Index table rows by grade level
rownames(sd.table) <- sd.table$grade
View(sd.table)

# // Step 2: Create lists of demographic markers and their grade/subject gaps to measure
#Initialize demographic markers where you want to measure gaps
dems <- c("male","lep")

#Create lists of grade/subject/subpop combos where want to test for gaps
#For each demographic marker
dem.male <- list( test1 = c(grade = 5, subject = "math_ss", group = c("F","M")),
                  test2 = c(grade = 8, subject = "math_ss", group = c("F","M")))
dem.lep  <- list( test1 = c(grade = 5, subject = "rdg_ss", group = c(0,1)),
                  test2 = c(grade = 8, subject = "rdg_ss", group = c(0,1)))

#Combine lists by demographic marker
test.lists <- list(male = dem.male, lep = dem.lep)

# // Step 3: Measure and sort median differences by school
#Loop over demographic marker
for(dem in dems){
  
  #Saves grade/subject lists for demographic marker
  tests <- test.lists[[dem]]
  
  #Loop over grade/subject/subpopulation combos
  for(test in tests){
    
    #Save grade, subject, and subpopulations
    grade <- test["grade"][[1]]
    subject <- test["subject"][[1]]
    group1 <- test["group1"][[1]]
    group2 <- test["group2"][[1]]
    
    data <- texas.data[texas.data$grade_level == grade,] #Isolates grade level
    data <- data[data[,dem]== group1 | data[,dem]== group2, ] #Isolates subpopulations
    
    #Finds overall district scaled median difference
    dis.meds <- tapply(data[,subject], data[,dem], median, na.rm=TRUE)
    dis.diff <- (dis.meds[group2] - dis.meds[group1])/sd.table[grade,subject]
    names(dis.diff) <- c("district")
    
    #Finds medians by school and demographic marker
    school.meds <- tapply(data[,subject], 
                          list(data$school_code, data[,dem]), 
                          median, na.rm=TRUE)
    
    #Finds gaps and scales by standard deviation
    differences <- (school.meds[,group2] - school.meds[,group1])/sd.table[grade,subject]
    differences <- c(differences, dis.diff) #include district-wide difference
    
    #Sorts the gaps (smallest to largest), converts to dataframe, appends distrist median difference
    differences <- differences[order(differences)]
    med_diff_table <- data.frame(school_code = names(differences),
                                   median_diff = differences)
    rownames(med_diff_table) <- NULL
    
    #Prints table of differences
    print(paste(labels[dem], ", difference of medians: ", 
                group2, " - ",group1))
    print(paste("Grade: ",grade,", ",labels[subject]))
    print(med_diff_table)
    cat("\n\n")
    
    #Shows barplot of school median differences
    barp <- ggplot(med_diff_table, aes(x= reorder(school_code, median_diff), y=median_diff)) +
                  geom_bar(position="dodge",stat="identity")+
                  scale_x_discrete(name = "School Code")+
                  scale_y_continuous(name = "Scaled Median Difference")+
                  ggtitle(paste("Grade",grade,labels[subject], 
                                "Median Differences ", labels[dem],
                                "(",group2, "-",group1,")"))
    
    print(barp)
    
  } # End loop over grade/subject/subpopulation combos

} # End loop over demographic markers

```

### Identifying Target Schools

**Purpose:** As a district leader or policymaker, the next step is to identify which campuses have the most underperforming students for the student populations in which we see the largest gaps district-wide. Those schools would be the ones to target with direct or indirect interventions, in order to fastest close the gap for the district overall.

**Required Analysis File Variables:**

- `grade_level` 
- `school_code` 
- `male`        
- `race_ethnicity` 
- `eco_dis`      
- `title_1`     
- `migrant`     
- `lep`
- `iep`
- `rdg_ss`
- `math_ss`
- `wrtg_ss`
- `composition`

**Ask Yourself**

- Which is more important in this analysis: identifying the school with the lowest median scores for a student population or identifying the campuses with the largest number of students (of our target population) performing below a certain benchmark?
- What types of interventions would be most useful for our target schools?

**Analytic Technique:** To get a sense of where students from our target student populations are performing the worst overall, we will calculate the median reading test scores at each campus among LEP students and median math test scores at each campus among female students. Again, we choose the medians here because they are less susceptible to skew and outliers. We will visualize these medians with bar charts, and we will visualize the lowest peforming schools with comparative box plots.

```{r MedianTargets, echo=TRUE}
# // Step 1: Initialize target populations, grade, and subject
#Initialize demographic markers where you want to measure gaps
dems <- c("male","lep")

#Create lists of grade/subject/subpop combos where want to measure medians
#For each demographic marker
dem.male <- list( test1 = c(grade = 5, subject = "math_ss", group = "F"),
                  test2 = c(grade = 8, subject = "math_ss", group = "F"))
dem.lep  <- list( test1 = c(grade = 5, subject = "rdg_ss", group = 1),
                  test2 = c(grade = 8, subject = "rdg_ss", group = 1))

#Combine lists by demographic marker
test.lists <- list(male = dem.male, lep = dem.lep)

# // Step 2: Measure and sort medians by school
#Loop over demographic marker
for(dem in dems){
  
  #Saves grade/subject lists for demographic marker
  tests <- test.lists[[dem]]
  
  #Loop over grade/subject/subpopulation combos
  for(test in tests){
    
    #Save grade, subject, and subpopulations
    grade <- test["grade"][[1]]
    subject <- test["subject"][[1]]
    group <- test["group"][[1]]
    
    data <- texas.data[texas.data$grade_level == grade,] #Isolates grade level
    data <- data[data[,dem]== group, ] #Isolates subpopulation
    
    #Finds overall district median
    dis.med <- median(data[,subject])
    names(dis.med) <- c("district")
    
    #Finds medians by school and demographic marker
    school.meds <- tapply(data[,subject], 
                          data$school_code, 
                          median, na.rm=TRUE)
    school.meds <- c(school.meds, dis.med) #include district-wide median
    
    #Sorts the medians (smallest to largest), converts to dataframe
    school.meds <- school.meds[order(school.meds)]
    med_table <- data.frame(school_code = names(school.meds),
                                   median = school.meds)
    rownames(med_table) <- NULL
    
    #Prints table of medians
    print(paste(labels[dem], group, " Medians"))
    print(paste("Grade: ",grade,", ",labels[subject]))
    print(med_table)
    cat("\n\n")
    
    #Shows barplot of school medians
    barp <- ggplot(med_table, aes(x= reorder(school_code, median), y=median)) +
                  geom_bar(stat="identity")+
                  geom_text(aes(label=round(median)), vjust=-0.25)+
                  scale_x_discrete(name = "School Code")+
                  scale_y_continuous(name = "Median Score")+
                  ggtitle(paste("Grade",grade,labels[subject], 
                                "Medians for", labels[dem],group,
                                ", by School"))
    
    print(barp)
    
    #Isolate data for lowest 3 schools
    low.schools <- as.character(med_table[1:3,"school_code"])
    data$school_code <- as.character(data$school_code)
    data.low <- data[data$school_code== low.schools, ]
    data.low$school_code <- factor(data.low$school_code, 
                                   levels = low.schools,ordered=TRUE)
    
    #Show box plots of 3 lowest schools and district overall
    boxp <- ggplot(data.low, aes(x=school_code , y=data.low[,subject])) +
                  geom_boxplot() +
                  geom_boxplot(data=data, aes(x = factor("district"), y = data[,subject]))+
                  scale_x_discrete(limits=c(low.schools,"district"),
                                   name="School Code")+
                  scale_y_continuous(name=labels[subject])+
                  ggtitle(paste("Lowest schools",labels[dem],group,",Grade",grade,labels[subject]))
    print(boxp)
    
  } # End loop over grade/subject/subpopulation combos

} # End loop over demographic markers

```


**Analytic Technique:** Although useful for getting an overall picture, looking at medians alone may not be the most effective way to identify target schools. Given that districts have limited resources, it may also be useful to take school size into account. For example, a small school may have the worst median LEP performance in your district. However, it could be more efficient to target a larger school with slightly higher median performance scores if that school has more low-performing LEP students overall. At the larger school, in theory, a new intervention effort could reach a greater number of lower-performing LEP students than at the smaller school. Of course, if this technique is used in isolation, it has the potential downside of consistently preferencing resources towards larger schools. The result could be perceived favoritism or discrimination. Therefore, this analysis should provide just one among several considerations when picking target schools.

In this analysis, we will attempt to isolate the raw number of students at each school in our target populations who are "under-performing". We will do this in two ways: 
1) We will look at the number of target students in each campus who scored below the district-wide median.
2) We will look at the number of target students at each campus who scored below the district-wide first quartile.

```{r RawNumberTargets, echo=TRUE}
## // Step 1: Initialize target populations, grade, and subject
##Initialize demographic markers where you want to measure gaps
dems <- c("male","lep")
#
##Create lists of target grade/subject/subpop combos
##For each demographic marker
dem.male <- list( test1 = c(grade = 5, subject = "math_ss", group = "F"),
                  test2 = c(grade = 8, subject = "math_ss", group = "F"))
dem.lep  <- list( test1 = c(grade = 5, subject = "rdg_ss", group = 1),
                  test2 = c(grade = 8, subject = "rdg_ss", group = 1))

##Combine lists by demographic marker
test.lists <- list(male = dem.male, lep = dem.lep)
#
## // Step 2: Measure and visualize number of underperforming students by school
##Loop over demographic marker
for(dem in dems){
  
  #Saves grade/subject lists for demographic marker
  tests <- test.lists[[dem]]
  
  #Loop over grade/subject/subpopulation combos
  for(test in tests){
    
    #Save grade, subject, and subpopulations
    grade <- test["grade"][[1]]
    subject <- test["subject"][[1]]
    group <- test["group"][[1]]
    
    data <- texas.data[texas.data$grade_level == grade,] #Isolates grade level
    
    #Calculates district median and first quartile scores for test
    dist.median <- median(data[,subject]) #district median
    dist.quant <- quantile(data[,subject])[["25%"]] #district first quartile
    
    data <- data[data[,dem]== group, ] #Isolates subpopulation
    data$below_med <- data[,subject] < dist.median #Adds indicator if below median
    data$below_quant <- data[,subject] < dist.quant #Adds indicator if below first quartile
    
    #Initialize vectors for a loop to get numbers below median and quartile and plot them
    cuts <- c("below_med","below_quant")
    cut.labels <- c("Below Median","Below First Quartile")
    names(cut.labels) <- cuts
    
    #Loop over median and quartile analysis
    for(cut in cuts){
      
      #Finds number of students at each school below cut
      school.data <- tapply(data[,cut], 
                          data$school_code, 
                          sum, na.rm=TRUE)
      school.data <- school.data[order(school.data, decreasing=TRUE)] #sort descending order
      school_table <- data.frame(school_code = names(school.data), #make into table
                                     count = school.data)
      rownames(school_table) <- NULL 
      
      #Prints table of counts for each school
      print(paste(labels[dem], group,",", cut.labels[cut]))
      print(paste("Grade: ",grade,", ",labels[subject]))
      print(school_table)
      cat("\n\n")
      
      #Shows barplot of number below cut by school
      barp <- ggplot(school_table, aes(x= reorder(school_code, -count), y=count)) +
                  geom_bar(stat="identity")+
                  geom_text(aes(label=count, vjust=-0.25))+
                  scale_x_discrete(name = "School Code")+
                  scale_y_continuous(name = paste("Number of students",cut.labels[cut]))+
                  ggtitle(paste("Grade",grade,labels[subject], 
                                "Number of", labels[dem],group,
                                "Students",cut.labels[cut],
                                ", by School"))
    
      print(barp)
      
    } #End loop over cuts
    
  } # End loop over grade/subject/subpopulation combos

} # End loop over demographic markers

```

### Isolating effects of covariates

**Purpose:** Students possess many individual and demographic features that simultaneously affect their education. It can be hard to determine, from an equity perspective, what factor most affects a student's ability to learn and achieve. 

For example, in the data, you may notice undocumented students generally score lower on reading tests. One could draw the conclusion from this trend that there exist direct barriers to achievement for undocumented students that the district or state must tackle. 

However, many undocumented students may be Limited English Proficient (LEP) learners. In many cases, LEP students in general also have lower reading scores, due to language barriers. So can the correlation between immigration status and lower scores be mostly explained by such language barriers? Or does the noticeable score effect from immigration status remain, even when we control for English proficiency level? Testing out this nuance, and others like it, can help a district hone its efforts and create better policy for under-performing student populations.

**Required Analysis File Variables:**

- `grade_level` 
- `school_code` 
- `male`        
- `race_ethnicity` 
- `eco_dis`      
- `title_1`     
- `migrant`     
- `lep`
- `iep`
- `rdg_ss`
- `math_ss`
- `wrtg_ss`
- `composition`

**Ask Yourself**

- Can we draw causal estimates from this type of analysis, or is it only correlatoinal?
- How do we best choose what controls we use in our equations?

**Analytic Technique:** We will be using using linear regression. We choose linear regression because our outcome variable (scale scores on tests) is approximately continuous, and the technique will allow us to come up with our correlatoin estimates while controlling for various factors. Here, we will look at Black/White and Hispanic/White achievement gaps in 8th grade math, when controlling for economic disadvantage level and LEP level.

```{r CoefficientAnalysis, echo=TRUE}
# // Step 1: Isolate the grade level we want (8th grade here)
data <- texas.data[texas.data$grade_level == 8,]

# // Step 2: Recode variables and create cluster variable
data$race_ethnicity <- as.factor(data$race_ethnicity)
data$race_ethnicity <- relevel(data$race_ethnicity, ref = "W")

# // Step 3: Create a unique identifier for clustering standard errors 
# at the school level
data$cluster_var <- data$school_code 

# Load the broom library to make working with model coefficients simple 
# and uniform
library(broom)

# // Step 4: Estimate the unadjusted and adjusted differences in 8th grade math  
# scores between Hispanic and white students and between black and white 
# students 

# Estimate unadjusted enrollment gap
#  Fit the model
mod1 <- lm(math_ss ~ race_ethnicity, data = data)
#  Extract the coefficients
betas_unadj <- tidy(mod1)
#  Get the clustered variance-covariance matrix
#  Use the get_CL_vcov function from the functions.R script
clusterSE <- get_CL_vcov(mod1, data$cluster_var)
#  Get the clustered standard errors and combine with the betas
betas_unadj$std.error <- sqrt(diag(clusterSE))
betas_unadj <- betas_unadj[, 1:3]
#  Label
betas_unadj$model <- "Unadjusted enrollment gap"

# Estimate score gap adjusting for economic disadvantage level
mod2 <- lm(math_ss ~ race_ethnicity + eco_dis, data = data)
betas_adj_eco_dis <- tidy(mod2)
clusterSE <- get_CL_vcov(mod2, data$cluster_var)
betas_adj_eco_dis$std.error <- sqrt(diag(clusterSE))
betas_adj_eco_dis <- betas_adj_eco_dis[, 1:3]
betas_adj_eco_dis$model <- "Gap adjusted for econ disadvantage"

# Estimate score gap adjusting for LEP status
mod3 <- lm(math_ss ~ race_ethnicity + lep, data = data)
betas_adj_lep <- tidy(mod3)
clusterSE <- get_CL_vcov(mod3, data$cluster_var)
betas_adj_lep$std.error <- sqrt(diag(clusterSE))
betas_adj_lep <- betas_adj_lep[, 1:3]
betas_adj_lep$model <- "Gap adjusted for LEP status"

# Estimate score gap adjusting for economic disadvantage level and LEP status
mod4 <- lm(math_ss ~ race_ethnicity + eco_dis + lep, 
           data = data)
betas_adj_ecodis_lep <- tidy(mod4)
clusterSE <- get_CL_vcov(mod4, data$cluster_var)
betas_adj_ecodis_lep$std.error <- sqrt(diag(clusterSE))
betas_adj_ecodis_lep <- betas_adj_ecodis_lep[, 1:3]
betas_adj_ecodis_lep$model <- "Gap adjusted for Eco_Dis level & LEP status"

# // Step 5. Transform the regression coefficients to a data object for plotting
chartData <- bind_rows(betas_unadj, betas_adj_eco_dis, betas_adj_lep, 
                    betas_adj_ecodis_lep)

# // Step 6. Plot

#Set y-axis limits
lim2 <- -(min(chartData[chartData$term == "race_ethnicityH", "estimate"])-1)
lim1 <- -(max(chartData[chartData$term == "race_ethnicityH", "estimate"])+1)

if(lim2 > 0 & lim1 > 0){
  
  lim1 <- -1
}

if(lim2 < 0 & lim1 < 0){
  
  lim2 <- 1
}

#Make barplot
ggplot(chartData[chartData$term == "race_ethnicityH", ],
       aes(x = model, y = -estimate, fill = model)) + 
        geom_bar(stat = 'identity', color = I("black")) + 
        scale_fill_brewer(type = "seq", palette = 8) +
        geom_hline(yintercept = 0) + 
        guides(fill = guide_legend("", keywidth = 6, nrow = 2)) + 
        geom_text(aes(label = -estimate, vjust = -0.3)) +
        scale_y_continuous(limit = c(lim1,lim2), name = "Scale Score") + 
        theme_classic() + theme(legend.position = "bottom", axis.text.x = element_blank(), 
                                axis.ticks.x = element_blank()) + 
        labs(title = "Differences in 8th Grade Math Scores Between Latino and White Students", 
             x = "")

```
